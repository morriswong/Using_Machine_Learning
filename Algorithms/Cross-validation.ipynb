{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "In machine learning predictive problems we apply the algorithms to certain dataset to crave the insights out of it (to build a model), so that the machine can automatically identify the objects in the future based on the insights it learned. To measure how accurate a model performs, we normally need to **validate** it after it is trained.\n",
    "\n",
    "The best way of validating a model is to apply it to the same kind of data it is trained on, and the easiest way of doing that is using the data we already have, splitting the data into two portions, one relatively bigger than another and train the model on it, and then test the model on the smaller portion.\n",
    "\n",
    "The result would tell you how well your model is.\n",
    "\n",
    "However, there's a very decent chance that we created an excessively complex model (such as having too many parameters relative to the number of observations), which is gonna lead to a problem called **overfitting**, which means that the model we created learned WAY TOO well from the training dataset, and performs relatively badly on the test dataset. **`Cross-validation`** helps us to know more about our model to solve this problem.\n",
    "\n",
    "**Cross Validation Goal**: Define a dataset to \"test\" the model in the training phase (i.e., the validation dataset), in order to limit problems like overfitting, give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset, for instance from a real problem), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation\n",
    "\n",
    "It splits the whole dataset into K partions, and recursively using one as the testing dataset and the rest as training dataset, give result evaluations to the model performance on each one of them, and average them to show how accurate the model is.\n",
    "\n",
    "![K-fold_cross_validation](https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of K-fold cross-validation\n",
    "\n",
    "\n",
    "\n",
    "#### Steps for cross-validation:\n",
    "\n",
    "- Dataset is split into K \"folds\" of equal size\n",
    "- Each fold acts as the testing set 1 time, and acts as the training set K-1 times\n",
    "- Average testing performance is used as the estimate of out-of-sample performance\n",
    "\n",
    "#### Benefits of cross-validation:\n",
    "\n",
    "- More reliable estimate of out-of-sample performance than train/test split\n",
    "- Can be used for selecting tuning parameters, choosing between models, and selecting features\n",
    "\n",
    "#### Drawbacks of cross-validation:\n",
    "\n",
    "- Can be computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
